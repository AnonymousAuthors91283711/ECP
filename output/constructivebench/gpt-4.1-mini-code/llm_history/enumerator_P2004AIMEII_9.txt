[write_program]
The problem involves analyzing a given integer sequence defined by initial values and a piecewise formula for \( n \geq 11 \). The goal is to find the largest \( n \) such that \( \text{seq}(n) < 1000 \) and then compute the sum \( n + \text{seq}(n) \). The sequence has linear or quadratic terms depending on parity.

We will:

- Implement the sequence in Python exactly as given.
- Find all \( n \leq 1000 \) with \( \text{seq}(n) < 1000 \).
- Print each \( n \) and \( \text{seq}(n) \) immediately when found.
- Track the maximum such \( n \) and output \( n + \text{seq}(n) \) at the end.

This will help conjecture the answer and cross-check given conditions.

```python
# enumerator.py

def seq(n):
    # Base cases
    base_vals = {1:1, 2:2, 3:4, 4:6, 5:9, 6:12, 7:16, 8:20, 9:25, 10:30}
    if n in base_vals:
        return base_vals[n]
    # For n >= 11
    if n % 2 == 1:
        return n * n
    else:
        return n * (n + 1)

def main():
    max_n = 0
    max_val = 0
    for n in range(1, 1001):
        val = seq(n)
        if val < 1000:
            print(f"n = {n}, seq(n) = {val}")
            if n > max_n:
                max_n = n
                max_val = val
    print(f"Maximum n with seq(n) < 1000: {max_n}")
    print(f"sum = n + seq(n) = {max_n} + {max_val} = {max_n + max_val}")

if __name__ == "__main__":
    main()
```
