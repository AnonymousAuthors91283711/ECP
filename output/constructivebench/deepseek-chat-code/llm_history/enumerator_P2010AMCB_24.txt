[write_program]
The problem involves finding the sum of lengths of intervals where a function f(x) is greater than 1, with f(x) defined as 1/(x+1) + 1/x + 1/(x-1). The solution involves three intervals: (-1, 1-√2), (0, 1/2), and (1, 1+√2). We need to verify these intervals and calculate their total length.

Here's a Python program that numerically verifies the intervals and calculates the total length:

```python
import math

def f(x):
    return 1/(x+1) + 1/x + 1/(x-1)

def verify_intervals():
    sqrt2 = math.sqrt(2)
    intervals = [
        (-1, 1 - sqrt2),
        (0, 0.5),
        (1, 1 + sqrt2)
    ]
    
    # Verify each interval
    for a, b in intervals:
        print(f"Checking interval ({a:.3f}, {b:.3f})")
        # Check sample points within the interval
        for x in [a + 0.1 * (b - a) * i for i in range(1, 5)]:
            if abs(x) < 1e-9: continue  # avoid division by zero
            fx = f(x)
            print(f"  f({x:.3f}) = {fx:.3f} {'>' if fx > 1 else '<='} 1")
    
    # Calculate total length
    total_length = (1 - sqrt2 - (-1)) + (0.5 - 0) + (1 + sqrt2 - 1)
    print(f"\nTotal length of intervals: {total_length:.5f}")

verify_intervals()
```

The program:
1. Defines the function f(x)
2. Lists the three intervals to verify
3. Checks sample points within each interval to confirm f(x) > 1
4. Calculates and prints the total length of all intervals

The output will show the verification of points within each interval and the final calculated length, which matches the mathematical expression (1 - √2 - (-1)) + (0.5 - 0) + (1 + √2 - 1).
