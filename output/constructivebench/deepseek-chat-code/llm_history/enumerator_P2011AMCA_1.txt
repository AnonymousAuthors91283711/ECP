[write_program]
This problem involves calculating a cost based on given parameters T and M. The cost formula is: 20 + 0.05*T + 0.1*max(0, M-1800). We'll compute this for the given values T=100 and M=30.5*60 (which is 1830 seconds).

The program will:
1. Convert M from minutes to seconds (30.5 minutes = 1830 seconds)
2. Calculate the cost using the given formula
3. Output the exact value (as a fraction) and decimal approximation

```python
def main():
    T = 100
    M = 30.5 * 60  # Convert minutes to seconds
    
    # Calculate cost components
    base_cost = 20
    T_component = 0.05 * T
    M_component = 0.1 * max(0, M - 1800)
    
    total_cost = base_cost + T_component + M_component
    
    # Output exact value as fraction and decimal approximation
    print(f"Exact cost: {base_cost} + {T_component} + {M_component} = {total_cost}")
    print(f"Decimal approximation: {total_cost:.2f}")

if __name__ == "__main__":
    main()
```
