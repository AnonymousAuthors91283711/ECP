[write_program]
The problem asks to find a unique polynomial \( P \) over \( \mathbb{Q} \) with degree at most 3 that satisfies:

- \( P \) agrees with the function \( f(x) = \frac{1}{1 + x + x^2} \) at points 1, 2, 3, and 4;
- and evaluate \( P \) at \( x=5 \).

Since \( P \) interpolates these four points, we can determine it explicitly using Lagrange interpolation. We will compute \( P(5) \) by constructing the polynomial. To do this numerically, we will evaluate the Lagrange basis polynomials at 5, then sum appropriately.

Here's a Python program that performs this calculation explicitly and sequentially for each point, confirming the polynomial evaluation at 5.

```python
# Define the points and function values
points = [1, 2, 3, 4]
values = [1/(1 + x + x**2) for x in points]

# Function to compute Lagrange basis polynomial at a given x
def lagrange_basis(i, x):
    numerator = 1
    denominator = 1
    xi = points[i]
    for j, xj in enumerate(points):
        if j != i:
            numerator *= (x - xj)
            denominator *= (xi - xj)
    return numerator / denominator

# Evaluate the interpolating polynomial at x=5
x_eval = 5
P_at_5 = 0
for i in range(4):
    basis = lagrange_basis(i, x_eval)
    P_at_5 += values[i] * basis
    print(f'Basis polynomial at {x_eval} for i={i}: {basis}')
print(f'Interpolated polynomial value at {x_eval}: {P_at_5}')
```
