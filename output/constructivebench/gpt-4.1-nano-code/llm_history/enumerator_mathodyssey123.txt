[write_program]
This problem involves finding the maximum possible sum of set A under certain constraints involving disjoint sets A and B, subsets of {0,...,20}. The constraints enforce relationships between A and B: for each n in A, 2n+2 must be in B, and A and B are disjoint. Our task is to find the greatest sum of A.

Since 2n + 2 in B implies that n in A must satisfy 2n + 2 not in A (because A and B are disjoint), and B is constructed from elements related to A, we can reformulate constraints to avoid conflicts and maximize the sum of A.

Given the size (up to 20), it is feasible to programmatically generate candidate sets A, check the constraints, compute sums, and keep track of the maximum.

Here's the approach:
- Loop over subsets of {0..20}.
- For each subset A, deduce B as {2n+2 | n in A}.
- Check disjointness and subset constraints.
- Keep track of the maximum sum of elements in A.

```python
# Enumerate all subsets of {0..20} to find the maximum sum of A under constraints
from itertools import combinations

max_sum = 0
max_A = set()

elements = range(21)
for r in range(22):
    for A_tuple in combinations(elements, r):
        A = set(A_tuple)
        B = {2 * n + 2 for n in A}
        # Check if B is subset of {0..20}
        if all(b <= 20 for b in B):
            # A and B must be disjoint
            if A.isdisjoint(B):
                s = sum(A)
                if s > max_sum:
                    max_sum = s
                    max_A = A
                    # Print each candidate with current max
                    print(f"New max sum {max_sum} with A = {sorted(A)}")
# Final output of the maximum sum
print(f"Maximum sum of A: {max_sum}")
```
